{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOGS VS CATS REDUX CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm trying to cover all the concepts covered in Lesson 1 through 7 with regard to CNN. The code runs on sample data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try '% + Tab' and it gives you a list of commands that can be run in the notebook just as if it were in the terminal.\n",
    "# Here we are checking the present working directory\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This command helps us to make and see plots within the notebook [a python 2D plotting library] \n",
    "%matplotlib inline\n",
    "\n",
    "#import modules that we will be using in the code\n",
    "from utils import *\n",
    "from vgg16 import Vgg16\n",
    "\n",
    "# Enter the path to your data in the working directory\n",
    "# path = \"data/redux/\" # Use this path if you are using the entire dataset\n",
    "path = \"data/redux/sample/\" # Use this path if you are using sample dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other imports. Add the imports as and when you are using any particular library\n",
    "import os,sys\n",
    "from shutil import copyfile\n",
    "import gc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Data Folders\n",
    "### This piece of code needs to be run only the very first time you run the code as they are one-time setups*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "%cd data/redux\n",
    "%mkdir valid\n",
    "%mkdir results\n",
    "%mkdir pred\n",
    "%mkdir -p sample/train\n",
    "%mkdir -p sample/test\n",
    "%mkdir -p sample/valid\n",
    "%mkdir -p sample/results\n",
    "%mkdir -p sample/pred\n",
    "%mkdir -p test/unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Move images to valid data folders from train data folder\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(2000): os.rename(shuf[i], '../valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy a few images to sample/train from train data folder\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(200): copyfile(shuf[i], '../sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../sample/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy a all the images in train folder to pred folder, for use during pseudo labeling\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(len(g)): copyfile(shuf[i], '../pred/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../../valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Copy a few images to sample/valid from valid data folder\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(50): copyfile(shuf[i], '../sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%cd ../test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copy all (or a few) the images in test folder to sample/test folder\n",
    "g = glob('*.jpg')\n",
    "shuf = np.random.permutation(g)\n",
    "for i in range(100): copyfile(shuf[i], '../sample/test/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rearrange all the images to separate dogs and cats directories \n",
    "# in the train, valid, sample/train, sample/valid directories\n",
    "%cd ../sample/train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd ../valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd ../../valid\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd ../train\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/\n",
    "\n",
    "%cd ../sample/pred\n",
    "%mkdir cats\n",
    "%mkdir dogs\n",
    "%mv cat.*.jpg cats/\n",
    "%mv dog.*.jpg dogs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a single 'unknown' class for test set as the code looks for sub-directories\n",
    "%cd ../test\n",
    "%mv *.jpg unknown/\n",
    "\n",
    "%cd ../../test\n",
    "%mv *.jpg unknown/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%cd ../../.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using a Trained Model and Finetuning it (VGG16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import Vgg16 helper class\n",
    "vgg = Vgg16()\n",
    "adam_model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use this command (you need to 'import gc') to free the RAM once in a while\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set batch size\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create batches of training and validation\n",
    "gen=image.ImageDataGenerator()\n",
    "batches = gen.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "val_batches = gen.flow_from_directory(path+'valid', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finetune the original model to suit our needs\n",
    "adam_model.pop()\n",
    "for layer in adam_model.layers: layer.trainable=False\n",
    "adam_model.add(Dense(batches.nb_class, activation='softmax'))\n",
    "adam_model.compile(optimizer=Adam(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Finetuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will train the new model with the changes which we have just made to it. Trains only the modified layers\n",
    "adam_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We can further train it using different learning rates and number of epochs\n",
    "adam_model.optimizer.lr = 0.001\n",
    "adam_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find out how the model is structured\n",
    "adam_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam_model.save_weights(path+'results/simple_vgg_Adam.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can change the optimizers and check how well the model trains for each optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel adam_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_model.pop()\n",
    "for layer in sgd_model.layers: layer.trainable=False\n",
    "sgd_model.add(Dense(batches.nb_class, activation='softmax'))\n",
    "sgd_model.compile(optimizer=SGD(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sgd_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sgd_model.save_weights(path+'results/simple_vgg_SGD.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel sgd_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rms_model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rms_model.pop()\n",
    "for layer in rms_model.layers: layer.trainable=False\n",
    "rms_model.add(Dense(batches.nb_class, activation='softmax'))\n",
    "rms_model.compile(optimizer=SGD(lr=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rms_model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rms_model.save_weights(path+'results/simple_vgg_RMSprop.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing all Dense Layers of VGG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no use retraining the convolutional layers of a pre-trained model considering that it is only extracting the features of the image that passes through it. Hence we can try to change the dense layers to make our model better for specific classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%xdel rms_model\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = vgg.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've added batchnormalization to the last convolutional layer and after each dense layers. Dropout and L1, L2 regularization too can be added at this point. But it is not advisable for sample data set as regularization is directly related to the amount of data we have; more the data, more regularization needs to be added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Batchnormalization, dropout, L2 regularization\n",
    "model.add(BatchNormalization(axis=1))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(2, activation='softmax', W_regularizer=l2(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/vgg_dense_replace.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize results i.e. to check how well the model is performing we use the validation dataset. The confusion matrix is used to see the performance of the model in a matrix form. This part is not necessary in the code, but helps us t understand what problems are being faced by the model in classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Free up the RAM a bit\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_preds = model.predict_generator(val_batches, val_samples = val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are the image names as we see in the folders\n",
    "filenames = val_batches.filenames\n",
    "# These are the labels for each image in the validation set (0 - cat, 1 - dog)\n",
    "expected_labels = val_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The predictions we get are rounded of to 0 or 1\n",
    "our_predictions = val_preds[:,0]\n",
    "our_labels = np.round(1-our_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "\n",
    "# Helper function to plot images by index in the validation set \n",
    "# Plots is a helper function in utils.py\n",
    "def plots_idx(idx, titles=None):\n",
    "    plots([image.load_img(path + 'valid/' + filenames[i]) for i in idx], titles=titles)\n",
    "    \n",
    "# Number of images to view for each visualization task\n",
    "n_view = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. A few correct labels at random\n",
    "correct = np.where(our_labels==expected_labels)[0]\n",
    "print \"Found %d correct labels\" % len(correct)\n",
    "idx = permutation(correct)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. A few incorrect labels at random\n",
    "incorrect = np.where(our_labels!=expected_labels)[0]\n",
    "print \"Found %d incorrect labels\" % len(incorrect)\n",
    "idx = permutation(incorrect)[:n_view]\n",
    "plots_idx(idx, our_predictions[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3a. The images we most confident were cats, and are actually cats\n",
    "correct_cats = np.where((our_labels==0) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct cats labels\" % len(correct_cats)\n",
    "most_correct_cats = np.argsort(our_predictions[correct_cats])[::-1][:n_view]\n",
    "plots_idx(correct_cats[most_correct_cats], our_predictions[correct_cats][most_correct_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3b. The images we most confident were dogs, and are actually dogs\n",
    "correct_dogs = np.where((our_labels==1) & (our_labels==expected_labels))[0]\n",
    "print \"Found %d confident correct dogs labels\" % len(correct_dogs)\n",
    "most_correct_dogs = np.argsort(our_predictions[correct_dogs])[:n_view]\n",
    "plots_idx(correct_dogs[most_correct_dogs], our_predictions[correct_dogs][most_correct_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4a. The images we were most confident were cats, but are actually dogs\n",
    "incorrect_cats = np.where((our_labels==0) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect cats\" % len(incorrect_cats)\n",
    "if len(incorrect_cats):\n",
    "    most_incorrect_cats = np.argsort(our_predictions[incorrect_cats])[::-1][:n_view]\n",
    "    plots_idx(incorrect_cats[most_incorrect_cats], our_predictions[incorrect_cats][most_incorrect_cats])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4b. The images we were most confident were dogs, but are actually cats\n",
    "incorrect_dogs = np.where((our_labels==1) & (our_labels!=expected_labels))[0]\n",
    "print \"Found %d incorrect dogs\" % len(incorrect_dogs)\n",
    "if len(incorrect_dogs):\n",
    "    most_incorrect_dogs = np.argsort(our_predictions[incorrect_dogs])[:n_view]\n",
    "    plots_idx(incorrect_dogs[most_incorrect_dogs], our_predictions[incorrect_dogs][most_incorrect_dogs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 5. The most uncertain labels (ie those with probability closest to 0.5).\n",
    "most_uncertain = np.argsort(np.abs(our_predictions-0.5))\n",
    "plots_idx(most_uncertain[:n_view], our_predictions[most_uncertain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(expected_labels, our_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, val_batches.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a set of images from train data using variations like rotate, height shift, width shift, etc.\n",
    "gen_t = image.ImageDataGenerator(rotation_range=15)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And train the model\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(height_shift_range=0.05)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And train the model\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(shear_range=0.1)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And train the model\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(channel_shift_range=20)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And train the model\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And train the model\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/data_aug.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate a set of images from train data by combining all the variations like rotate, height shift, width shift, etc.\n",
    "gen_t = image.ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.05, shear_range=0.1, channel_shift_range=20, \n",
    "                                 rotation_range=15)\n",
    "\n",
    "batches = gen_t.flow_from_directory(path+'train', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=3,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/data_aug_all.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the weights of the model that has given you the best accuracy\n",
    "model.load_weights(path+'results/data_aug_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Run the code for the test images and classify them\n",
    "test_batches = gen.flow_from_directory(path+'test', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "test_feat = model.predict_generator(test_batches, val_samples = test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_filenames = test_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Store the result into an excel sheet\n",
    "result_name = path+'results/result.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx): return np.clip(arr, (1-mx)/9, mx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subm = do_clip(test_feat,0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classes = sorted(batches.class_indices, key=batches.class_indices.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(subm, columns=classes)\n",
    "submission.insert(0, 'img', [a[4:] for a in test_filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_excel(result_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from openpyxl import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wb = load_workbook(path+'results/result.xlsx')\n",
    "sheet = wb.get_sheet_by_name('Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(2, test_batches.nb_sample):\n",
    "    if sheet.cell(row=i, column=2).value > sheet.cell(row=i, column=3).value:\n",
    "        col = 2\n",
    "    else: col = 3\n",
    "    img = sheet.cell(row=i,column=1).value\n",
    "    f = sheet.cell(row=1, column = col).value\n",
    "    %cd data/state/sample/test/unknown\n",
    "    g = glob('*.jpg')\n",
    "    for i in range (test_batches.nb_sample):\n",
    "        if g[i]==str(img):\n",
    "            copyfile(g[i], '../../pred/' + str(f) + '/' + g[i])\n",
    "    %cd ../../../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate the new set of training batches\n",
    "pred_batches = gen.flow_from_directory(path+'pred', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model with the new set of data\n",
    "model.fit_generator(batches, samples_per_epoch=batches.nb_sample, nb_epoch=5,\n",
    "                validation_data=val_batches, nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save_weights(path+'results/pseudo_label.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We test the model using the test data made available. Note: Here we are using the original test folder with all data\n",
    "test_batches = gen.flow_from_directory(path+'../test', target_size=(224,224), \n",
    "                                  class_mode='categorical', shuffle=True, batch_size=batch_size)\n",
    "preds = model.predict_generator(test_batches, val_samples = test_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Working on the dog prediction column\n",
    "isdog = preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We shall round our predictions on the edges\n",
    "isdog = isdog.clip(min=0.05, max=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Extract image ID of the filenames from the /test/unknown directory\n",
    "filenames = test_batches.filenames\n",
    "ids = np.array([int(f[8:f.find('.')]) for f in filenames])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#We join the two columns into an array for submission\n",
    "subm = np.stack([ids,isdog], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Save it as a .csv file\n",
    "%cd $path/results\n",
    "submission_filename = 'submission1.csv'\n",
    "np.savetxt(submission_filename, subm, fmt='%d,%.5f', header='id,label', comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(path+'results/'+submission_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
